"""
Extrator de usu√°rios do ServiceNow com sincroniza√ß√£o incremental
"""

import hashlib
from datetime import datetime, timedelta
from typing import List, Optional, Set

import polars as pl

from config import get_db_connection

from .base_extractor import BaseServiceNowExtractor


class UserExtractor(BaseServiceNowExtractor):
    """Extrator espec√≠fico para usu√°rios (sys_user) com sincroniza√ß√£o inteligente"""

    def __init__(self):
        super().__init__()
        self.table_name = "sys_user"
        self.api_endpoint = "sys_user"

    def extract_data(self, force_full_sync: bool = False) -> pl.DataFrame:
        """
        Extrai dados de usu√°rios de forma incremental

        Args:
            force_full_sync: Se True, for√ßa sincroniza√ß√£o completa
        """
        print(f"üë• Iniciando extra√ß√£o de usu√°rios (sys_user)")
        force_full_sync = True
        if force_full_sync:
            print("üîÑ Sincroniza√ß√£o COMPLETA for√ßada")
            return self._extract_all_users()
        else:
            print("‚ö° Sincroniza√ß√£o INCREMENTAL (apenas mudan√ßas)")
            return self._extract_incremental_users()

    def _extract_all_users(self) -> pl.DataFrame:
        """Extrai todos os usu√°rios (sincroniza√ß√£o completa)"""
        print("üì• Buscando todos os usu√°rios...")

        # Busca todos os usu√°rios ativos primeiro
        params = {
            "sysparm_query": "active=true",
            "sysparm_fields": self._get_user_fields(),
        }

        active_users = self.paginated_request(self.api_endpoint, params)
        print(f"‚úÖ {len(active_users)} usu√°rios ativos encontrados")

        # Busca tamb√©m usu√°rios inativos que foram modificados recentemente (√∫ltimos 30 dias)
        cutoff_date = (datetime.now() - timedelta(days=30)).strftime(
            "%Y-%m-%d %H:%M:%S"
        )
        params_inactive = {
            "sysparm_query": f"active=false^sys_updated_on>={cutoff_date}",
            "sysparm_fields": self._get_user_fields(),
        }

        inactive_users = self.paginated_request(
            self.api_endpoint, params_inactive
        )
        print(
            f"‚úÖ {len(inactive_users)} usu√°rios inativos modificados recentemente"
        )

        # Combina todos os usu√°rios
        all_users = active_users + inactive_users

        # Remove duplicatas baseado no sys_id
        seen_ids = set()
        unique_users = []
        for user in all_users:
            if user.get("sys_id") not in seen_ids:
                unique_users.append(user)
                seen_ids.add(user.get("sys_id"))

        print(f"‚úÖ Total de {len(unique_users)} usu√°rios √∫nicos extra√≠dos")

        if unique_users:
            # Processa dados e adiciona hash para controle
            processed_users = self._process_and_hash_users(unique_users)
            return pl.DataFrame(processed_users)
        else:
            return pl.DataFrame()

    def _extract_incremental_users(self) -> pl.DataFrame:
        """Extrai apenas usu√°rios modificados recentemente"""

        # 1. Determina data de √∫ltima sincroniza√ß√£o
        last_sync_date = self._get_last_sync_date()
        print(f"üìÖ √öltima sincroniza√ß√£o: {last_sync_date}")

        # 2. Busca usu√°rios modificados desde a √∫ltima sincroniza√ß√£o
        query = f"sys_updated_on>={last_sync_date}"

        params = {
            "sysparm_query": query,
            "sysparm_fields": self._get_user_fields(),
        }

        modified_users = self.paginated_request(self.api_endpoint, params)
        print(
            f"‚úÖ {len(modified_users)} usu√°rios modificados desde {last_sync_date}"
        )

        if modified_users:
            # Processa dados e adiciona hash
            processed_users = self._process_and_hash_users(modified_users)

            # 3. Identifica quais realmente mudaram (usando hash)
            users_to_update = self._filter_changed_users(processed_users)
            print(
                f"üîÑ {len(users_to_update)} usu√°rios com mudan√ßas reais detectadas"
            )

            if users_to_update:
                return pl.DataFrame(users_to_update)

        print("‚ÑπÔ∏è Nenhuma mudan√ßa detectada nos usu√°rios")
        return pl.DataFrame()

    def _get_user_fields(self) -> str:
        """Define campos a serem extra√≠dos da API de usu√°rios"""
        fields = [
            # Campos b√°sicos
            "sys_id",
            "user_name",
            "name",
            "first_name",
            "last_name",
            "middle_name",
            # Contato
            "email",
            "phone",
            "mobile_phone",
            # Organizacional
            "company",
            "department",
            "location",
            "manager",
            "title",
            # Status
            "active",
            "locked_out",
            "web_service_access_only",
            # Login
            "last_login",
            "last_login_time",
            "failed_attempts",
            # Configura√ß√µes
            "time_zone",
            "date_format",
            "time_format",
            # Auditoria
            "sys_created_on",
            "sys_created_by",
            "sys_updated_on",
            "sys_updated_by",
        ]

        return ",".join(fields)

    def _process_and_hash_users(self, users: List[dict]) -> List[dict]:
        """Processa usu√°rios e adiciona hash para controle de mudan√ßas"""
        processed_users = []

        for user in users:
            # Processa campos de refer√™ncia
            processed_user = self.process_data([user])[0]

            # Adiciona timestamps ETL
            processed_user["etl_created_at"] = datetime.now()
            processed_user["etl_updated_at"] = datetime.now()

            # Calcula hash dos dados principais (exclui campos de auditoria ETL)
            hash_data = {
                k: v
                for k, v in processed_user.items()
                if not k.startswith("etl_")
                and k not in ["sys_created_on", "sys_updated_on"]
            }

            data_string = str(sorted(hash_data.items()))
            processed_user["etl_hash"] = hashlib.md5(
                data_string.encode()
            ).hexdigest()

            processed_users.append(processed_user)

        return processed_users

    def _filter_changed_users(self, users: List[dict]) -> List[dict]:
        """Filtra apenas usu√°rios que realmente mudaram (baseado no hash)"""
        if not users:
            return []

        changed_users = []

        try:
            with get_db_connection() as conn:
                cursor = conn.cursor()

                for user in users:
                    # Busca hash atual no banco
                    query = "SELECT etl_hash FROM sys_user WHERE sys_id = ?"
                    cursor.execute(query, user["sys_id"])
                    result = cursor.fetchone()

                    if result is None:
                        # Usu√°rio novo
                        print(
                            f"‚ûï Novo usu√°rio: {user.get('user_name', user.get('sys_id'))}"
                        )
                        changed_users.append(user)
                    elif result[0] != user["etl_hash"]:
                        # Usu√°rio modificado
                        print(
                            f"üîÑ Usu√°rio modificado: {user.get('user_name', user.get('sys_id'))}"
                        )
                        changed_users.append(user)
                    # Caso contr√°rio, usu√°rio n√£o mudou (hash igual)

        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao filtrar usu√°rios alterados: {e}")
            print("‚ÑπÔ∏è Retornando todos os usu√°rios por seguran√ßa")
            return users

        return changed_users

    def _get_last_sync_date(self) -> str:
        """Obt√©m data da √∫ltima sincroniza√ß√£o de usu√°rios"""
        default_date = (datetime.now() - timedelta(days=7)).strftime(
            "%Y-%m-%d %H:%M:%S"
        )

        try:
            with get_db_connection() as conn:
                cursor = conn.cursor()

                # Busca √∫ltima atualiza√ß√£o na tabela de usu√°rios
                query = "SELECT MAX(etl_updated_at) FROM sys_user"
                cursor.execute(query)
                result = cursor.fetchone()

                if result and result[0]:
                    # Subtrai 1 hora para garantir sobreposi√ß√£o
                    last_update = result[0] - timedelta(hours=1)
                    return last_update.strftime("%Y-%m-%d %H:%M:%S")

        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao obter √∫ltima sincroniza√ß√£o: {e}")

        print(f"‚ÑπÔ∏è Usando data padr√£o: {default_date}")
        return default_date

    def get_users_by_ids(self, user_ids: Set[str]) -> pl.DataFrame:
        """
        Busca usu√°rios espec√≠ficos por IDs (para resolver refer√™ncias)

        Args:
            user_ids: Set de IDs de usu√°rios para buscar
        """
        if not user_ids:
            return pl.DataFrame()

        print(f"üîç Buscando {len(user_ids)} usu√°rios espec√≠ficos por ID...")

        # Divide em lotes para evitar URLs muito longas
        batch_size = 50
        all_users = []

        user_ids_list = list(user_ids)
        for i in range(0, len(user_ids_list), batch_size):
            batch_ids = user_ids_list[i : i + batch_size]
            ids_query = "^OR".join([f"sys_id={uid}" for uid in batch_ids])

            params = {
                "sysparm_query": ids_query,
                "sysparm_fields": self._get_user_fields(),
            }

            batch_users = self.paginated_request(self.api_endpoint, params)
            all_users.extend(batch_users)
            print(
                f"üì• Lote {i // batch_size + 1}: {len(batch_users)} usu√°rios"
            )

        print(f"‚úÖ Total de {len(all_users)} usu√°rios espec√≠ficos extra√≠dos")

        if all_users:
            processed_users = self._process_and_hash_users(all_users)
            return pl.DataFrame(processed_users)
        else:
            return pl.DataFrame()

    def get_missing_user_ids_from_incidents(self) -> Set[str]:
        """Identifica IDs de usu√°rios referenciados em incidentes mas n√£o presentes na tabela sys_user"""
        missing_ids = set()

        try:
            with get_db_connection() as conn:
                cursor = conn.cursor()

                # Busca IDs √∫nicos de usu√°rios referenciados em incidentes
                query = """
                SELECT DISTINCT user_id
                FROM (
                    SELECT resolved_by as user_id FROM incident WHERE resolved_by IS NOT NULL
                    UNION
                    SELECT opened_by as user_id FROM incident WHERE opened_by IS NOT NULL
                    UNION  
                    SELECT caller_id as user_id FROM incident WHERE caller_id IS NOT NULL
                ) as all_user_refs
                WHERE user_id NOT IN (SELECT sys_id FROM sys_user)
                """

                cursor.execute(query)
                results = cursor.fetchall()

                for row in results:
                    missing_ids.add(row[0])

                print(
                    f"üîç {len(missing_ids)} usu√°rios referenciados mas n√£o encontrados na tabela"
                )

        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao identificar usu√°rios em falta: {e}")

        return missing_ids

    def sync_missing_users(self) -> pl.DataFrame:
        """Sincroniza usu√°rios que est√£o referenciados em incidentes mas faltam na tabela"""
        print("üîÑ Sincronizando usu√°rios em falta...")

        missing_ids = self.get_missing_user_ids_from_incidents()

        if missing_ids:
            return self.get_users_by_ids(missing_ids)
        else:
            print("‚úÖ Todos os usu√°rios referenciados j√° est√£o sincronizados")
            return pl.DataFrame()


def main():
    """Fun√ß√£o para testar o extractor"""
    extractor = UserExtractor()

    print("üß™ TESTANDO EXTRACTOR DE USU√ÅRIOS")
    print("=" * 50)

    # Teste incremental
    df_incremental = extractor.extract_data(force_full_sync=False)
    print(f"üìä Usu√°rios incrementais: {len(df_incremental)} registros")

    # Teste de usu√°rios em falta
    df_missing = extractor.sync_missing_users()
    print(f"üìä Usu√°rios em falta: {len(df_missing)} registros")

    print("‚úÖ Teste conclu√≠do!")


if __name__ == "__main__":
    main()
